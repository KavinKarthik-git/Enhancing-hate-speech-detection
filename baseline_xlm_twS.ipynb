{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14134,"status":"ok","timestamp":1699062359227,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"39ea1973-e66a-44d8-843b-d67a364157e2","outputId":"dc32eaf7-e289-4671-d36e-c43806a31809"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: safetensors, dill, multiprocess, huggingface-hub, tokenizers, transformers, datasets\n","Successfully installed datasets-2.14.6 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"]}],"source":["! pip install transformers datasets\n"],"id":"39ea1973-e66a-44d8-843b-d67a364157e2"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5387,"status":"ok","timestamp":1699062364610,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"XUdi-aVbfwdE","outputId":"9f3a2fe8-9ed8-4d02-9318-77d7633b43c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.1/1.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["! pip install sentencepiece"],"id":"XUdi-aVbfwdE"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3954,"status":"ok","timestamp":1699062368558,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"oqOigbHbfvLS","outputId":"22b37e5f-ba28-46cb-aca8-bd0bff52fab6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}],"source":["import torch\n","torch.cuda.empty_cache()\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"],"id":"oqOigbHbfvLS"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14914,"status":"ok","timestamp":1699062383465,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"a5vsYl5PcZIs","outputId":"8f1b1cf2-40c6-41fa-fff6-0ce9fb7ec206"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"id":"a5vsYl5PcZIs"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BWYFQcUkcMOt"},"outputs":[],"source":["import os\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""],"id":"BWYFQcUkcMOt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad239020-27bb-4886-8c61-e1908e57e506"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from torch import optim\n","import sys\n","import random\n","import math\n","import time\n","from tqdm import tqdm\n","from sklearn.metrics import precision_recall_fscore_support, f1_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from transformers import BertTokenizer, AutoTokenizer\n","from transformers import BertModel, AutoModel, AutoModelForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","from torch.utils.tensorboard import SummaryWriter\n","\n","use_cuda = True if torch.cuda.is_available() else False\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# use_cuda=False\n","# device='cpu'\n","\n","torch.autograd.set_detect_anomaly(True)\n","torch.backends.cudnn.benchmark = True\n","np.random.seed(0)\n","torch.manual_seed(0)\n","\n","base_model = 'twitter-xlm-roberta-base-sentiment'\n","model_list = ['bert-base-uncased', 'bert-base-multilingual-uncased', 'google/muril-base-cased', 'xlm-roberta-base',\n","              'ai4bharat/indic-bert','cardiffnlp/twitter-xlm-roberta-base','cardiffnlp/twitter-xlm-roberta-base-sentiment',\n","              'cardiffnlp/twitter-roberta-base', 'cardiffnlp/twitter-roberta-base-sentiment',\n","              'cardiffnlp/twitter-roberta-base-hate', 'roberta-base']\n","model_path = '/content/drive/MyDrive/saved_models/'\n","results_path = '/content/drive/MyDrive/saved_results/'"],"id":"ad239020-27bb-4886-8c61-e1908e57e506"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0da5f88b-0f84-4c67-8eba-8a90b0095c5a"},"outputs":[],"source":["lang = 'portuguese'\n","model_choice = 6"],"id":"0da5f88b-0f84-4c67-8eba-8a90b0095c5a"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1699062440053,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"99050998-e6fc-4236-b022-6b337c2aad28","outputId":"4ed10dd9-da9c-4aa7-d909-0e78e969fdb1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":8}],"source":["writer = SummaryWriter(log_dir=\"/content/drive/MyDrive/\" + base_model + \"_\" + lang)\n","device"],"id":"99050998-e6fc-4236-b022-6b337c2aad28"},{"cell_type":"markdown","metadata":{"id":"kKB9QasAslSP"},"source":["BASELINE"],"id":"kKB9QasAslSP"},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDs1ZklGskYs"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_list[model_choice])\n","\n","MAX_SEQ_LEN = 128\n","\n","label_idx = 1\n","text_idx = 0\n","\n","class HateData_Baseline(Dataset):\n","    def __init__(self, data_path, split='train', lang='bengali', aug_prob=0.2, flip_prob=0.5):\n","        self.split = split\n","        self.data = pd.read_csv(data_path + split + \"_\" + lang + \".tsv\", sep='\\t', lineterminator='\\n')\n","\n","        if self.split == 'train':\n","            self.label2data = {0:[], 1:[], 2:[]}\n","            # self.data = self.data[self.data['language'] == lang]\n","\n","            for i in tqdm(range(len(self.data))):\n","                row = self.data.iloc[i]\n","                self.label2data[row[label_idx]].append(row[text_idx])\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","    def __getitem__(self, index):\n","        if torch.is_tensor(index):\n","            index = index.tolist()\n","\n","        data = self.data.iloc[index]\n","\n","        labels = data[label_idx]\n","        text = data[text_idx]\n","        inputs = tokenizer(text, padding='max_length', truncation=True, max_length=MAX_SEQ_LEN)\n","        # print(inputs)\n","        input_ids = inputs['input_ids']\n","        token_type_ids = np.zeros(MAX_SEQ_LEN)#inputs['token_type_ids']#\n","        attn_mask = inputs['attention_mask']\n","\n","        aug_text = text\n","        labels_aug = labels\n","\n","        inputs_aug = tokenizer(aug_text, padding='max_length', truncation=True, max_length=MAX_SEQ_LEN)\n","        # print(inputs)\n","        input_ids_aug = inputs_aug['input_ids']\n","        token_type_ids_aug = np.zeros(MAX_SEQ_LEN)#inputs_aug['token_type_ids']#\n","        attn_mask_aug = inputs_aug['attention_mask']\n","\n","        input_ids = torch.tensor(np.vstack([input_ids, input_ids_aug]), dtype=torch.long).view(2, MAX_SEQ_LEN)\n","        token_type_ids = torch.tensor(np.vstack([token_type_ids, token_type_ids_aug]), dtype=torch.long).view(2, MAX_SEQ_LEN)\n","        attn_mask = torch.tensor(np.vstack([attn_mask, attn_mask_aug]), dtype=torch.long).view(2, MAX_SEQ_LEN)\n","        labels = torch.tensor(np.vstack([labels, labels_aug]), dtype=torch.long).view(2)\n","\n","\n","        return input_ids, attn_mask, token_type_ids, labels\n"],"id":"PDs1ZklGskYs"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cf8548d8-c91b-4ccf-a518-0635f05579ef"},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","\n","        H1, H2, num_class = 768, 128, 2\n","        self.bert = AutoModel.from_pretrained(model_list[model_choice])\n","\n","        # for param in self.bert.parameters():\n","        #     param.requires_grad = False\n","\n","        self.clf = nn.Sequential(\n","            nn.Linear(H1, H2),\n","            nn.ReLU(),\n","            nn.Linear(H2, H2),\n","            nn.ReLU(),\n","            nn.Linear(H2, num_class)\n","        )\n","\n","\n","    def forward(self, input_ids, attn_mask, token_type_ids):\n","        outputs = self.bert(input_ids, attn_mask)#, token_type_ids)\n","        cls_emb = outputs.pooler_output # (batch, 768)\n","        logits = self.clf(cls_emb) # (batch, num_class)\n","        return logits\n"],"id":"cf8548d8-c91b-4ccf-a518-0635f05579ef"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9bbaa46-9b44-49af-bb49-124e9af439ba"},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()#"],"id":"b9bbaa46-9b44-49af-bb49-124e9af439ba"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9a4d0548-5e3d-4279-ad0b-1d9d566d3f90"},"outputs":[],"source":["def train(input_ids, attn_mask, token_type_ids, label, model, model_opt, scdl):\n","\n","    model_opt.zero_grad()\n","\n","    batch_size = input_ids.shape[0]\n","    seq_len = input_ids.shape[1]\n","\n","    loss = 0.0\n","\n","    if use_cuda:\n","        input_ids = input_ids.to(device)\n","        attn_mask = attn_mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        label = label.to(device)\n","\n","    # label = label.flatten()\n","\n","    logits = model(input_ids[:,0,:], attn_mask[:,0,:], token_type_ids[:,0,:])\n","    logits_aug = model(input_ids[:,1,:], attn_mask[:,1,:], token_type_ids[:,1,:])\n","\n","    loss = loss_fn(logits, label[:,0]) + loss_fn(logits_aug, label[:,1])\n","\n","    # if torch.isnan(loss):\n","    #     pass\n","    # else:\n","    loss.backward()\n","    # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients to prevent exploding\n","    model_opt.step()\n","    scdl.step()\n","    # print(loss)\n","    return float(loss.item())\n","\n"],"id":"9a4d0548-5e3d-4279-ad0b-1d9d566d3f90"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ad57855-ee8b-448e-9c03-0049d81db476"},"outputs":[],"source":["def evaluate(input_ids, attn_mask, token_type_ids, label, model, mode='train'):\n","\n","    batch_size = input_ids.shape[0]\n","    seq_len = input_ids.shape[1]\n","\n","\n","    with torch.no_grad():\n","        if use_cuda:\n","            input_ids = input_ids.to(device)\n","            attn_mask = attn_mask.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            label = label.to(device)\n","\n","        # label = label.flatten()\n","\n","        logits = model(input_ids[:,0,:], attn_mask[:,0,:], token_type_ids[:,0,:])\n","        loss = loss_fn(logits, label[:,0])\n","\n","        if mode == 'train':\n","            return float(loss.item())\n","\n","        preds = torch.argmax(logits, dim=1).flatten()\n","        # acc = (preds == label).cpu().numpy().mean() * 100\n","\n","        return float(loss.item()), preds.cpu().numpy()\n","\n","\n"],"id":"9ad57855-ee8b-448e-9c03-0049d81db476"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFXbb5WOvV_N"},"outputs":[],"source":["df_test = pd.read_csv(\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/test_portuguese.tsv\", sep='\\t', lineterminator='\\n')\n","gt_labels = np.array(df_test['label'])"],"id":"QFXbb5WOvV_N"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1699062467473,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"DLd1miwzvZ-a","outputId":"747bf3ff-9c87-4e32-f76b-7c92eb1707f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["284"]},"metadata":{},"execution_count":18}],"source":["len(gt_labels)"],"id":"DLd1miwzvZ-a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dabe9a9f-e8a6-4712-bf00-ae5d75d16bd5"},"outputs":[],"source":["def trainIters(model, epochs, train_loader, test_loader, learning_rate=3e-5, log_step=168, valid_step=168, mode='train'):\n","\n","    model_opt = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n","    num_train_steps = (len(train_loader)*epochs)\n","    scdl = get_linear_schedule_with_warmup(model_opt, num_warmup_steps=int(0.1*num_train_steps), num_training_steps=num_train_steps)\n","\n","    print(\"Initialised optimizer and lr scheduler\")\n","\n","    # valid_best_loss = []\n","    best_acc = 0.0\n","    tot = len(train_data) // train_loader.batch_size\n","    tot_val = len(val_data) // test_loader.batch_size\n","    plot_steps = 0\n","\n","    for epoch in range(epochs):\n","        train_loss_total = 0.0\n","        train_step = 0\n","        # Training\n","\n","        model.train()\n","        for entry in tqdm(train_loader, total=tot, position=0, leave=True):\n","            loss = train(entry[0], entry[1], entry[2], entry[3], model, model_opt, scdl)\n","            plot_steps += 1\n","            train_step += 1\n","            # if not math.isnan(loss) :\n","            train_loss_total = train_loss_total + loss\n","\n","            train_loss = train_loss_total / train_step\n","\n","            if plot_steps % log_step == 0:\n","                writer.add_scalar(\"Train Loss\", train_loss, plot_steps)\n","\n","            if (plot_steps % valid_step == 0) or (plot_steps >= num_train_steps - 1):\n","                model.eval()\n","                test_pred = []\n","\n","                for entry in tqdm(test_loader, total=tot_val, position=0, leave=True):\n","                    loss_v, pred_v = evaluate(entry[0], entry[1], entry[2], entry[3], model, mode='test')\n","                    # if not math.isnan(loss) :\n","                    test_pred.extend([pd for pd in pred_v])\n","\n","                # val_acc = (test_pred == gt_labels).mean().item()\n","                val_acc = f1_score(gt_labels, test_pred, average='macro')\n","                print(\"Validation F1: \" + str(val_acc))\n","                writer.add_scalar(\"Val F1\", val_acc, plot_steps)\n","\n","\n","                #   Save best model\n","                # state = {\n","                #         'epoch': epoch,\n","                #         'state_dict': model.state_dict(),\n","                #         'optimizer': model_opt.state_dict(),\n","                #         'loss': train_loss,\n","                #         'scheduler': scdl.state_dict(),\n","                # }\n","\n","\n","                if val_acc > best_acc:\n","                    torch.save(model.state_dict(), model_path + \"model_\" + base_model + \"_\" + lang + \"_easymix_mono_redo\" + \".pth\")\n","                    print(\"Model saved for step: \" + str(plot_steps))\n","                    best_acc = val_acc\n","\n","                model.train()\n","            writer.flush()\n","\n","\n","        print('epoch: '+str(epoch))\n","        print('total loss: '+str(train_loss_total/tot))\n","\n","        # wr_train = open(results_path + \"train_loss_\" + base_model + \".txt\", \"a\")\n","        # wr_train.write(\"epoch \" + str(epoch) + \": \" + str(train_loss_total/tot) + \"\\n\")\n","        # wr_train.close()\n","\n","\n"],"id":"dabe9a9f-e8a6-4712-bf00-ae5d75d16bd5"},{"cell_type":"markdown","metadata":{"id":"JCZZM6JNf55D"},"source":["For Base Model"],"id":"JCZZM6JNf55D"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":795,"status":"ok","timestamp":1699062479841,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"ed2a7f13-faa6-4e64-857e-4b47eea70546","outputId":"eb114d82-e49e-46ac-a64f-4beed7986c0b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5386/5386 [00:00<00:00, 15261.85it/s]\n"]}],"source":["train_data = HateData_Baseline(data_path=\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/\", split='train', lang=lang)\n","val_data = HateData_Baseline(data_path=\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/\", split='test', lang=lang)"],"id":"ed2a7f13-faa6-4e64-857e-4b47eea70546"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0410c5b-dd55-4523-9ce0-247538308727"},"outputs":[],"source":["BS = 16\n","# weights = [1.0]*15383\n","# weights.extend([0.5]*(len(train_data) - 15383))\n","# sampler = WeightedRandomSampler(weights, num_samples=20000)\n","\n","dataload = DataLoader(train_data, batch_size=BS, shuffle=True)\n","dataload_val = DataLoader(val_data, batch_size=BS, shuffle=False)"],"id":"c0410c5b-dd55-4523-9ce0-247538308727"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1699062484247,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"552520b0-9b62-440a-b8db-5e8468514759","outputId":"6615dc72-dcf3-4c0a-b719-cff6a1ba3da5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["168.0"]},"metadata":{},"execution_count":22}],"source":["(len(train_data)/16)//2"],"id":"552520b0-9b62-440a-b8db-5e8468514759"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["6ea824c433f440449efae0417de9dd54","da5961993d1a48969474a1c50a2c592b","116f4623ebbf4a9fb5250b1cf33ba8cc","ef92a5a7434d450dbc8ed9f2705770e0","a14133c2082f4d6b8a4a0623022e8d22","27ddea44135741fa9589c9eb5ef4a3cc","fc8b33c904fb46c087efc1aa17db9d4f","31f0323931ee4aa5b8bcab522a6a17e4","84c4bd5a2a8a4e8ebce055be49e3525c","1fcd60c3822946cf8c29bdb82a1ac16b","03044ed4e4384374a9895ed71dd27348"]},"executionInfo":{"elapsed":33484,"status":"ok","timestamp":1699062520479,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"47dbc8a3-d7fc-4ab9-8b82-ea95cac708d3","outputId":"3a980db4-067f-4cf8-9d37-415cccbe40a2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ea824c433f440449efae0417de9dd54"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = Classifier()\n","model = model.to(device)"],"id":"47dbc8a3-d7fc-4ab9-8b82-ea95cac708d3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"62b6aaed-5664-4b8f-b2b5-717104c11c16","executionInfo":{"status":"ok","timestamp":1699064543369,"user_tz":240,"elapsed":404227,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"}},"outputId":"db78a6a0-b2ff-4a54-e3cb-e45f997d00e0"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Initialised optimizer and lr scheduler\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.52it/s]                        \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.6576938529529932\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 168/336 [03:25<07:30,  2.68s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model saved for step: 168\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.64it/s]                        \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.7302696078431372\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r100%|██████████| 336/336 [06:47<00:00,  2.62s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model saved for step: 336\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["337it [06:48,  1.21s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch: 0\n","total loss: 1.112069038142051\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.60it/s]                        \n"," 50%|████▉     | 167/336 [03:17<05:05,  1.81s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.6966622162883844\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.63it/s]                        \n","100%|█████████▉| 335/336 [06:36<00:01,  1.78s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.7236514018123215\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["337it [06:38,  1.18s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch: 1\n","total loss: 0.8054257637510697\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.58it/s]                        \n"," 49%|████▉     | 166/336 [03:20<05:09,  1.82s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.6695478723404256\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.56it/s]                        \n"," 99%|█████████▉| 334/336 [06:41<00:03,  1.81s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.6851624948946846\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["337it [06:45,  1.20s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch: 2\n","total loss: 0.5392092773469076\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.61it/s]                        \n"," 49%|████▉     | 165/336 [03:16<05:05,  1.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.6718360396521317\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["18it [00:02,  8.61it/s]                        \n"," 99%|█████████▉| 333/336 [06:35<00:05,  1.81s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation F1: 0.6999517024873221\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["337it [06:39,  1.19s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch: 3\n","total loss: 0.32132702810867203\n"]},{"output_type":"stream","name":"stderr","text":["18it [00:02,  8.52it/s]                        \n"," 49%|████▉     | 164/336 [03:14<05:10,  1.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation F1: 0.6999517024873221\n"]},{"output_type":"stream","name":"stderr","text":["18it [00:02,  8.61it/s]                        \n"," 99%|█████████▉| 332/336 [06:35<00:07,  1.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation F1: 0.700947700947701\n"]},{"output_type":"stream","name":"stderr","text":["18it [00:02,  8.58it/s]                        \n","100%|██████████| 336/336 [06:41<00:00,  1.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation F1: 0.700947700947701\n"]},{"output_type":"stream","name":"stderr","text":["18it [00:02,  8.62it/s]                        \n","337it [06:45,  1.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation F1: 0.700947700947701\n","epoch: 4\n","total loss: 0.19139745278793963\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["trainIters(model, 5, dataload, dataload_val)"],"id":"62b6aaed-5664-4b8f-b2b5-717104c11c16"},{"cell_type":"markdown","metadata":{"id":"c1cfb1fe-2c3d-4f0d-b21d-21ce57faa3e5"},"source":["######################## TESTING ######################"],"id":"c1cfb1fe-2c3d-4f0d-b21d-21ce57faa3e5"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19bbbce2-7488-4118-ba55-8a88b7d67a03","executionInfo":{"status":"ok","timestamp":1699064559175,"user_tz":240,"elapsed":5861,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"}},"outputId":"4ca772a0-ba35-41ad-e493-02e5c7fc0141"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = Classifier()\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/saved_models/model_twitter-xlm-roberta-base-sentiment_\" + lang + \"_easymix_mono\" + \"_redo.pth\", map_location=device))\n","model = model.to(device)"],"id":"19bbbce2-7488-4118-ba55-8a88b7d67a03"},{"cell_type":"code","source":["lang='french'"],"metadata":{"id":"o2s2almj2ytq"},"id":"o2s2almj2ytq","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bb602bc-5bc9-4da0-a92a-3798f2b91dca"},"outputs":[],"source":["# test_data = HateData(data_path=\"/home/jupyter/data/test_data/bq_test_\" + lang + \"_process_10k.csv\")\n","test_data = HateData_Baseline(data_path=\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/\", split='test', lang=lang)\n","test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"],"id":"1bb602bc-5bc9-4da0-a92a-3798f2b91dca"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":888,"status":"ok","timestamp":1699064576795,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"1d3a48d8-f73b-41ff-98e9-4ba1734cb2cc","outputId":"0f98f3a3-4b6e-4b6e-b7ff-a41cb5a8df85"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 52/52 [00:00<00:00, 65.86it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss:  0.4976036666104427\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model.eval()\n","test_loss = []\n","test_pred = []\n","\n","# wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \"_process_10k.txt\", \"w\")\n","wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \".txt\", \"w\")\n","for entry in tqdm(test_loader, total=len(test_data)//test_loader.batch_size, position=0, leave=True):\n","    v_loss, v_pred = evaluate(entry[0], entry[1], entry[2], entry[3], model, mode='test')\n","    test_loss.append(v_loss)\n","    test_pred.append(v_pred)\n","    wr.write(str(v_pred)+\"\\n\")\n","\n","test_loss = np.mean(test_loss)#.item()\n","\n","print(\"Test Loss: \", test_loss)\n","\n","wr.close()"],"id":"1d3a48d8-f73b-41ff-98e9-4ba1734cb2cc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb8b4197-be6d-44f1-b67d-89f8d3834b75"},"outputs":[],"source":["df_test = pd.read_csv(\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/test_french.tsv\", sep='\\t', lineterminator='\\n')\n","gt_labels = np.array(df_test['label'])"],"id":"fb8b4197-be6d-44f1-b67d-89f8d3834b75"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":131,"status":"ok","timestamp":1699064582395,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"id":"8d23d212-69ff-400c-a4e9-36173cae12a4","outputId":"7bb056e6-da9e-4442-fb82-fb616a771772"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.8889    0.8889    0.8889        45\n","           1     0.2857    0.2857    0.2857         7\n","\n","    accuracy                         0.8077        52\n","   macro avg     0.5873    0.5873    0.5873        52\n","weighted avg     0.8077    0.8077    0.8077        52\n","\n"]}],"source":["print(classification_report(gt_labels, test_pred, digits=4))"],"id":"8d23d212-69ff-400c-a4e9-36173cae12a4"},{"cell_type":"code","source":["lang='spanish'"],"metadata":{"id":"__f99PJX_EQo"},"execution_count":null,"outputs":[],"id":"__f99PJX_EQo"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tu_f8DF1_EQp"},"outputs":[],"source":["# test_data = HateData(data_path=\"/home/jupyter/data/test_data/bq_test_\" + lang + \"_process_10k.csv\")\n","test_data = HateData_Baseline(data_path=\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/\", split='test', lang=lang)\n","test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"],"id":"Tu_f8DF1_EQp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19955,"status":"ok","timestamp":1699064615693,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"outputId":"d7256e39-2334-4ce3-8b26-58d984bea2f4","id":"ZddvMqLR_EQp"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [00:19<00:00, 80.87it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss:  0.6310936303786002\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model.eval()\n","test_loss = []\n","test_pred = []\n","\n","# wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \"_process_10k.txt\", \"w\")\n","wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \".txt\", \"w\")\n","for entry in tqdm(test_loader, total=len(test_data)//test_loader.batch_size, position=0, leave=True):\n","    v_loss, v_pred = evaluate(entry[0], entry[1], entry[2], entry[3], model, mode='test')\n","    test_loss.append(v_loss)\n","    test_pred.append(v_pred)\n","    wr.write(str(v_pred)+\"\\n\")\n","\n","test_loss = np.mean(test_loss)#.item()\n","\n","print(\"Test Loss: \", test_loss)\n","\n","wr.close()"],"id":"ZddvMqLR_EQp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4gXCwcxn_EQp"},"outputs":[],"source":["df_test = pd.read_csv(\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/test_spanish.tsv\", sep='\\t', lineterminator='\\n')\n","gt_labels = np.array(df_test['label'])"],"id":"4gXCwcxn_EQp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1699064649208,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"outputId":"e970488a-3134-4e42-c696-43c6fa1edf1e","id":"TQ-6WSAU_EQp"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.7572    0.5904    0.6635       940\n","           1     0.5559    0.7303    0.6313       660\n","\n","    accuracy                         0.6481      1600\n","   macro avg     0.6566    0.6604    0.6474      1600\n","weighted avg     0.6742    0.6481    0.6502      1600\n","\n"]}],"source":["print(classification_report(gt_labels, test_pred, digits=4))"],"id":"TQ-6WSAU_EQp"},{"cell_type":"code","source":["lang='arab'"],"metadata":{"id":"sikMdtXy_RfZ"},"execution_count":null,"outputs":[],"id":"sikMdtXy_RfZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0t2IAbbf_Rfa"},"outputs":[],"source":["# test_data = HateData(data_path=\"/home/jupyter/data/test_data/bq_test_\" + lang + \"_process_10k.csv\")\n","test_data = HateData_Baseline(data_path=\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/\", split='test', lang=lang)\n","test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"],"id":"0t2IAbbf_Rfa"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3434,"status":"ok","timestamp":1699064665714,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"outputId":"cdf1aafe-acc9-49d0-f489-8184a4c0d0cf","id":"LCldDvfL_Rfb"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 271/271 [00:03<00:00, 82.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss:  0.497606654036309\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model.eval()\n","test_loss = []\n","test_pred = []\n","\n","# wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \"_process_10k.txt\", \"w\")\n","wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \".txt\", \"w\")\n","for entry in tqdm(test_loader, total=len(test_data)//test_loader.batch_size, position=0, leave=True):\n","    v_loss, v_pred = evaluate(entry[0], entry[1], entry[2], entry[3], model, mode='test')\n","    test_loss.append(v_loss)\n","    test_pred.append(v_pred)\n","    wr.write(str(v_pred)+\"\\n\")\n","\n","test_loss = np.mean(test_loss)#.item()\n","\n","print(\"Test Loss: \", test_loss)\n","\n","wr.close()"],"id":"LCldDvfL_Rfb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDZ6cIAG_Rfb"},"outputs":[],"source":["df_test = pd.read_csv(\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/test_arab.tsv\", sep='\\t', lineterminator='\\n')\n","gt_labels = np.array(df_test['label'])"],"id":"yDZ6cIAG_Rfb"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1699064670880,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"outputId":"3f1e793c-b583-4e5a-ba2f-b3378ae456a8","id":"3BFnNeiP_Rfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.8930    0.8348    0.8629       230\n","           1     0.3214    0.4390    0.3711        41\n","\n","    accuracy                         0.7749       271\n","   macro avg     0.6072    0.6369    0.6170       271\n","weighted avg     0.8065    0.7749    0.7885       271\n","\n"]}],"source":["print(classification_report(gt_labels, test_pred, digits=4))"],"id":"3BFnNeiP_Rfc"},{"cell_type":"code","source":["lang='portuguese'"],"metadata":{"id":"3JhhIEdd_4j3"},"execution_count":null,"outputs":[],"id":"3JhhIEdd_4j3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QF5gSEb_4j3"},"outputs":[],"source":["# test_data = HateData(data_path=\"/home/jupyter/data/test_data/bq_test_\" + lang + \"_process_10k.csv\")\n","test_data = HateData_Baseline(data_path=\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/\", split='test', lang=lang)\n","test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"],"id":"4QF5gSEb_4j3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3973,"status":"ok","timestamp":1699064679908,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"outputId":"909d205a-fa11-4ee8-d614-994d137d063c","id":"TFdaGIU6_4j4"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 284/284 [00:03<00:00, 79.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss:  0.49076671531082877\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model.eval()\n","test_loss = []\n","test_pred = []\n","\n","# wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \"_process_10k.txt\", \"w\")\n","wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \".txt\", \"w\")\n","for entry in tqdm(test_loader, total=len(test_data)//test_loader.batch_size, position=0, leave=True):\n","    v_loss, v_pred = evaluate(entry[0], entry[1], entry[2], entry[3], model, mode='test')\n","    test_loss.append(v_loss)\n","    test_pred.append(v_pred)\n","    wr.write(str(v_pred)+\"\\n\")\n","\n","test_loss = np.mean(test_loss)#.item()\n","\n","print(\"Test Loss: \", test_loss)\n","\n","wr.close()"],"id":"TFdaGIU6_4j4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UltHreR8_4j4"},"outputs":[],"source":["df_test = pd.read_csv(\"/content/drive/MyDrive/data_efficient_hatedetect/data/multilingual/test_portuguese.tsv\", sep='\\t', lineterminator='\\n')\n","gt_labels = np.array(df_test['label'])"],"id":"UltHreR8_4j4"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1699062218693,"user":{"displayName":"Farina Faiz","userId":"02434960851545998007"},"user_tz":240},"outputId":"84294ab4-f0aa-4f34-da21-3d0b1c73c56b","id":"SUd2tiDi_4j4"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.8284    0.8622    0.8450       196\n","           1     0.6625    0.6023    0.6310        88\n","\n","    accuracy                         0.7817       284\n","   macro avg     0.7455    0.7323    0.7380       284\n","weighted avg     0.7770    0.7817    0.7787       284\n","\n"]}],"source":["print(classification_report(gt_labels, test_pred, digits=4))"],"id":"SUd2tiDi_4j4"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"environment":{"kernel":"python3","name":"common-cu110.m89","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cu110:m89"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6ea824c433f440449efae0417de9dd54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da5961993d1a48969474a1c50a2c592b","IPY_MODEL_116f4623ebbf4a9fb5250b1cf33ba8cc","IPY_MODEL_ef92a5a7434d450dbc8ed9f2705770e0"],"layout":"IPY_MODEL_a14133c2082f4d6b8a4a0623022e8d22"}},"da5961993d1a48969474a1c50a2c592b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27ddea44135741fa9589c9eb5ef4a3cc","placeholder":"​","style":"IPY_MODEL_fc8b33c904fb46c087efc1aa17db9d4f","value":"Downloading pytorch_model.bin: 100%"}},"116f4623ebbf4a9fb5250b1cf33ba8cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31f0323931ee4aa5b8bcab522a6a17e4","max":1112271561,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84c4bd5a2a8a4e8ebce055be49e3525c","value":1112271561}},"ef92a5a7434d450dbc8ed9f2705770e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fcd60c3822946cf8c29bdb82a1ac16b","placeholder":"​","style":"IPY_MODEL_03044ed4e4384374a9895ed71dd27348","value":" 1.11G/1.11G [00:21&lt;00:00, 41.1MB/s]"}},"a14133c2082f4d6b8a4a0623022e8d22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27ddea44135741fa9589c9eb5ef4a3cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc8b33c904fb46c087efc1aa17db9d4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31f0323931ee4aa5b8bcab522a6a17e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c4bd5a2a8a4e8ebce055be49e3525c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fcd60c3822946cf8c29bdb82a1ac16b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03044ed4e4384374a9895ed71dd27348":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}